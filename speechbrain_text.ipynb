{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kompiel/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.inference import EncoderDecoderASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch normalizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch asr.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-conformer-transformerlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: normalizer, asr, lm, tokenizer\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.0.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.0.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.0.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.0.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.0.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.0.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.0.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.0.multihead_attn.att.out_proj.bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.1.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.1.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.1.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.1.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.1.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.1.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.1.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.1.multihead_attn.att.out_proj.bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.2.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.2.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.2.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.2.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.2.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.2.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.2.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.2.multihead_attn.att.out_proj.bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.3.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.3.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.3.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.3.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.3.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.3.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.3.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.3.multihead_attn.att.out_proj.bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.4.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.4.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.4.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.4.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.4.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.4.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.4.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.4.multihead_attn.att.out_proj.bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.5.mutihead_attn.att.in_proj_weight']`->`state_dict['1.decoder.layers.5.multihead_attn.att.in_proj_weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.5.mutihead_attn.att.in_proj_bias']`->`state_dict['1.decoder.layers.5.multihead_attn.att.in_proj_bias']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.5.mutihead_attn.att.out_proj.weight']`->`state_dict['1.decoder.layers.5.multihead_attn.att.out_proj.weight']`\n",
      "INFO:speechbrain.utils.checkpoints:Due to replacement compatibility rule '.mutihead_attn'->'.multihead_attn', renamed `state_dict['1.decoder.layers.5.mutihead_attn.att.out_proj.bias']`->`state_dict['1.decoder.layers.5.multihead_attn.att.out_proj.bias']`\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.15 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m asr_model \u001b[38;5;241m=\u001b[39m EncoderDecoderASR\u001b[38;5;241m.\u001b[39mfrom_hparams(source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain/asr-conformer-transformerlm-librispeech\u001b[39m\u001b[38;5;124m\"\u001b[39m, savedir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/kompiel/.cache/speechbrain/asr-transformer-transformerlm-librispeech\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_opts\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43masr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/kompiel/python_scripts/asr-evaluate/data/pilot0026_01_01_original_240sec.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/inference/ASR.py:93\u001b[0m, in \u001b[0;36mEncoderDecoderASR.transcribe_file\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m batch \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m rel_length \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])\n\u001b[0;32m---> 93\u001b[0m predicted_words, predicted_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_length\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_words[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/inference/ASR.py:157\u001b[0m, in \u001b[0;36mEncoderDecoderASR.transcribe_batch\u001b[0;34m(self, wavs, wav_lens)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    156\u001b[0m     wav_lens \u001b[38;5;241m=\u001b[39m wav_lens\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 157\u001b[0m     encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransducer_beam_search:\n\u001b[1;32m    159\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m [encoder_out]\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/inference/ASR.py:124\u001b[0m, in \u001b[0;36mEncoderDecoderASR.encode_batch\u001b[0;34m(self, wavs, wav_lens)\u001b[0m\n\u001b[1;32m    122\u001b[0m wavs \u001b[38;5;241m=\u001b[39m wavs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    123\u001b[0m wavs, wav_lens \u001b[38;5;241m=\u001b[39m wavs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), wav_lens\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 124\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_beam_search:\n\u001b[1;32m    126\u001b[0m     encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmods\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mencode(encoder_out, wav_lens)\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/nnet/containers.py:209\u001b[0m, in \u001b[0;36mLengthsCapableSequential.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m    207\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x, lengths\u001b[38;5;241m=\u001b[39mlengths)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/lobes/models/transformer/TransformerASR.py:693\u001b[0m, in \u001b[0;36mEncoderWrapper.forward\u001b[0;34m(self, x, wav_lens, pad_idx, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, wav_lens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pad_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    692\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Processes the input tensor x and returns an output tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 693\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/lobes/models/transformer/TransformerASR.py:517\u001b[0m, in \u001b[0;36mTransformerASR.encode\u001b[0;34m(self, src, wav_len, pad_idx, dynchunktrain_config)\u001b[0m\n\u001b[1;32m    514\u001b[0m     src \u001b[38;5;241m=\u001b[39m src \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(src)\n\u001b[1;32m    515\u001b[0m     pos_embs_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_embs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_embs_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynchunktrain_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynchunktrain_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_hidden_states:\n\u001b[1;32m    526\u001b[0m     encoder_out, _, hidden_states \u001b[38;5;241m=\u001b[39m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/lobes/models/transformer/Conformer.py:749\u001b[0m, in \u001b[0;36mConformerEncoder.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, pos_embs, dynchunktrain_config)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, enc_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerdrop_prob \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m keep_probs[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerdrop_prob\n\u001b[1;32m    748\u001b[0m     ):\n\u001b[0;32m--> 749\u001b[0m         output, attention \u001b[38;5;241m=\u001b[39m \u001b[43menc_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpos_embs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_embs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynchunktrain_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynchunktrain_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m         attention_lst\u001b[38;5;241m.\u001b[39mappend(attention)\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_hidden_states:\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/lobes/models/transformer/Conformer.py:474\u001b[0m, in \u001b[0;36mConformerEncoderLayer.forward\u001b[0;34m(self, x, src_mask, src_key_padding_mask, pos_embs, dynchunktrain_config)\u001b[0m\n\u001b[1;32m    471\u001b[0m skip \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    472\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[0;32m--> 474\u001b[0m x, self_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_embs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_embs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m skip\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# convolution module\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/nnet/attention.py:675\u001b[0m, in \u001b[0;36mRelPosMHAXL.forward\u001b[0;34m(self, query, key, value, pos_embs, key_padding_mask, attn_mask, return_attn_weights)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# (batch, num_heads, klen, 2*klen-1)\u001b[39;00m\n\u001b[1;32m    672\u001b[0m matrix_bd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\n\u001b[1;32m    673\u001b[0m     q_with_bias_v \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, p_k\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    674\u001b[0m )\n\u001b[0;32m--> 675\u001b[0m matrix_bd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_bd\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shifting trick\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# if klen != qlen:\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m#   import ipdb\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m#  ipdb.set_trace(\u001b[39;00m\n\u001b[1;32m    681\u001b[0m attn_score \u001b[38;5;241m=\u001b[39m matrix_ac \u001b[38;5;241m+\u001b[39m matrix_bd  \u001b[38;5;66;03m# already scaled above\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/speechbrain/nnet/attention.py:536\u001b[0m, in \u001b[0;36mRelPosMHAXL.rel_shift\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    534\u001b[0m b, h, qlen, pos_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# (b, h, t1, t2)\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# need to add a column of zeros on the left side of last dimension to perform the relative shifting\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (b, h, t1, t2+1)\u001b[39;00m\n\u001b[1;32m    537\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(b, h, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, qlen)  \u001b[38;5;66;03m# (b, h, t2+1, t1)\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# need to drop the first row\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asr-evaluate/lib/python3.10/site-packages/torch/nn/functional.py:4522\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   4516\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4518\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4519\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_replication_pad(\n\u001b[1;32m   4520\u001b[0m                 \u001b[38;5;28minput\u001b[39m, pad\n\u001b[1;32m   4521\u001b[0m             )\n\u001b[0;32m-> 4522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.15 GiB. GPU "
     ]
    }
   ],
   "source": [
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-conformer-transformerlm-librispeech\", savedir=\"/home/kompiel/.cache/speechbrain/asr-transformer-transformerlm-librispeech\", run_opts={\"device\":\"cuda\"})\n",
    "result = asr_model.transcribe_file(\"/home/kompiel/python_scripts/asr-evaluate/data/pilot0026_01_01_original_240sec.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-evaluate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
